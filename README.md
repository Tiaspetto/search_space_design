# Awesome Paper in neural network Search Space Design on Convolutional Neural Networks

## Benchmarks and Search Space
| Title | Venue | Code |
|:--------|:--------:|:--------:|
| [NAS-Bench-101: Towards Reproducible Neural Architecture Search](https://arxiv.org/pdf/1902.09635.pdf) | ICML 2019 | [GitHub](https://github.com/google-research/nasbench) |
| [NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search](https://openreview.net/forum?id=HJxyZkBKDr) | ICLR 2020 | [Github](https://github.com/D-X-Y/NAS-Bench-201) |
| [NAS-Bench-301 and the Case for Surrogate Benchmarks for Neural Architecture Search](https://arxiv.org/abs/2008.09777) | arXiv 2020 | [GitHub](https://github.com/automl/nasbench301) |
| [NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search](https://arxiv.org/abs/2001.10422) | ICLR 2020 | [GitHub](https://github.com/automl/nasbench-1shot1) |
| [NATS-Bench: Benchmarking NAS Algorithms for Architecture Topology and Size](https://arxiv.org/abs/2009.00437) | TPAMI 2021 | [GitHub](https://github.com/D-X-Y/NATS-Bench)
| [HW-NAS-Bench: Hardware-Aware Neural Architecture Search Benchmark](https://openreview.net/pdf?id=_0kaDkv3dVf) | ICLR 2021 |  |
| [NDS: On Network Design Spaces for Visual Recognition](https://arxiv.org/pdf/1905.13214v1.pdf)|ICCV 2019| [GitHub](https://github.com/facebookresearch/nds)|
| [NAS-Bench-Macro: Prioritized Architecture Sampling with Monto-Carlo Tree Search](https://arxiv.org/abs/2103.11922)|CVPR2021|[GitHub](https://github.com/xiusu/NAS-Bench-Macro)|
|[Evolving Search Space for Neural Architecture Search](https://arxiv.org/pdf/2011.10904.pdf)|||
| [Designing Network Design Spaces](https://arxiv.org/pdf/2003.13678.pdf) | CVPR  | [GitHub](https://github.com/facebookresearch/pycls) |
| [Densely Connected Search Space for More Flexible Neural Architecture Search](https://arxiv.org/abs/1906.09607) | CVPR | [Github](https://github.com/JaminFong/DenseNAS) |

## NAS without training
| Title | Venue | Code |
|:--------|:--------:|:--------:|
| [Neural Architecture Search without Training](https://arxiv.org/abs/2006.04647v3) | ICML 2021 | [Github](https://github.com/BayesWatch/nas-without-training) |
| [Zero-Cost Proxies for Lightweight NAS](https://openreview.net/pdf?id=0cmMMy8J5q) | ICLR | |
| [Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective](https://openreview.net/forum?id=Cnon5ezMHtu) | ICLR  | [GitHub](https://github.com/VITA-Group/TENAS) |
|[Zero-Cost Proxies Meet Differentiable Architecture Search](https://arxiv.org/pdf/2106.06799v1.pdf)|||
|[On the Number of Linear Regions of Convolutional Neural Networks](https://arxiv.org/pdf/2006.00978.pdf)| PMLR2020| [GitHub](https://github.com/huangleiBuaa/LRCount-CNN)|
|[On the Number of Linear Regions of Deep Neural Networks](https://arxiv.org/pdf/1402.1869.pdf)]|||
|[NTK: Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent](https://arxiv.org/pdf/1902.06720v4.pdf)|||

## SOTA Network Structures
| Title | Venue | Code |
|:--------|:--------:|:--------:|
| [RegNet: Self-Regulated Network for Image Classification](https://arxiv.org/pdf/2101.00590v1.pdf) || [Github](https://github.com/BayesWatch/nas-without-training) |
| [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/pdf/1905.11946.pdf)|PMLR2019|[GitHub](https://arxiv.org/pdf/1905.11946.pdf)|
| [EfficientNetV2: Smaller Models and Faster Training](https://arxiv.org/pdf/2104.00298.pdf)| PMLR2021| [GitHub](https://arxiv.org/pdf/2104.00298.pdf)|
| [EfficientNet-X: Searching for Fast Model Families on Datacenter Accelerators](https://arxiv.org/pdf/2102.05610v1.pdf)|||
| [TResNet: High Performance GPU-Dedicated Architecture](https://arxiv.org/pdf/2003.13630.pdf)||[GitHub](https://arxiv.org/pdf/2003.13630.pdf)|
| [NFNet: High-Performance Large-Scale Image Recognition Without Normalization](https://arxiv.org/pdf/2102.06171v1.pdf)||[GitHub](https://github.com/deepmind/deepmind-research/tree/master/nfnets)|
| [LambdaNetworks: Modeling long-range Interactions without Attention](LambdaNetworks: Modeling long-range Interactions without Attention)|ICLR2021|[GitHub](https://github.com/d-li14/lambda.pytorch)|
| [BotNet:  Bottleneck transformers for visual recognition](https://arxiv.org/pdf/2101.11605v1.pdf)|CVPR2021|[GitHub](https://github.com/leaderj1001/BottleneckTransformers)|
| [Big transfer (bit): General visual representation learning](https://arxiv.org/pdf/1912.11370v3.pdf)||[GitHub](https://github.com/google-research/big_transfer)|
| [Fast and Accurate Model Scaling](https://arxiv.org/pdf/2103.06877v1.pdf)|CVPR2021|[GitHub](https://github.com/facebookresearch/pycls)|

## SOTA Vision Transformer
| Title | Venue | Code |
|:--------|:--------:|:--------:|
| [ViT: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://openreview.net/forum?id=YicbFdNTTy)|ICLR2021|[GitHub](https://github.com/gupta-abhay/ViT)|
| [Training data-efficient image transformers& distillation through attention](https://arxiv.org/pdf/2012.12877.pdf)||[GitHub](https://github.com/facebookresearch/deit)|
| [Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet](https://arxiv.org/pdf/2101.11986v2.pdf)|CVPR2021|[GitHub](https://github.com/yitu-opensource/T2T-ViT)|



